{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f60a8d6-af7e-4855-aaa5-b87e44604202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 14:10:08.416701: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-12 14:10:08.712269: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-12 14:10:08.722378: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:08.722389: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-12 14:10:08.756686: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-12 14:10:09.728337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:09.728434: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:09.728448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 1000)              5000      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 50)                50050     \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 300)               15300     \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 3)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,253\n",
      "Trainable params: 71,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 14:10:11.401436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-12 14:10:11.401676: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:11.401726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:11.401756: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:11.401782: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:11.401807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:11.401843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:11.401896: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:11.402016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-12 14:10:11.402023: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-12 14:10:11.402317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87799dd4-9d83-47c2-b686-82bf8d1beb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 21:37:30.629801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-13 21:37:30.736245: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-13 21:37:30.739957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-13 21:37:30.739969: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-13 21:37:30.760784: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-13 21:37:31.300616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-13 21:37:31.300684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-13 21:37:31.300691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries \n",
    "import keras #library for neural network\n",
    "import pandas as pd #loading data in table form  \n",
    "import seaborn as sns #visualisation \n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import normalize #machine learning algorithm library\n",
    "\n",
    "#  Load the dataset, which contains the data points(sepal length, petal length, etc) and corresponding labels(type of iris)\n",
    "iris_dataset=pd.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "\n",
    "iris_dataset.loc[iris_dataset[\"species\"]==\"setosa\",\"species\"]=0\n",
    "iris_dataset.loc[iris_dataset[\"species\"]==\"versicolor\",\"species\"]=1\n",
    "iris_dataset.loc[iris_dataset[\"species\"]==\"virginica\",\"species\"]=2\n",
    "\n",
    "# #This is a debug statement to make sure we uploaded the dataset correctly. \n",
    "# #We can comment it out when we actually run the code.\n",
    "# #print(iris_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd856ec2-4d76-485a-a91a-2f401758f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width species\n",
       "0             5.1          3.5           1.4          0.2       0\n",
       "1             4.9          3.0           1.4          0.2       0\n",
       "2             4.7          3.2           1.3          0.2       0\n",
       "3             4.6          3.1           1.5          0.2       0\n",
       "4             5.0          3.6           1.4          0.2       0\n",
       "..            ...          ...           ...          ...     ...\n",
       "145           6.7          3.0           5.2          2.3       2\n",
       "146           6.3          2.5           5.0          1.9       2\n",
       "147           6.5          3.0           5.2          2.0       2\n",
       "148           6.2          3.4           5.4          2.3       2\n",
       "149           5.9          3.0           5.1          1.8       2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56130560-693c-406f-9cdd-8e7ef35be11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# Break the dataset up into the examples (X) and their labels (y)\n",
    "X = iris_dataset.iloc[:, 0:4].values\n",
    "y = iris_dataset.iloc[:, 4].values\n",
    "X=normalize(X,axis=0)\n",
    "\n",
    "# Split up the X and y datasets randomly into train and test sets\n",
    "# 20% of the dataset will be used for the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=31)\n",
    "\n",
    "#Change the label to one hot vector\n",
    "'''\n",
    "[0]--->[1 0 0]\n",
    "[1]--->[0 1 0]\n",
    "[2]--->[0 0 1]\n",
    "'''\n",
    "y_train=np_utils.to_categorical(y_train,num_classes=3)\n",
    "y_test=np_utils.to_categorical(y_test,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97402c80-0c0e-45f6-82f1-a7f0ca5934ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "prediction=model.predict(X_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "#how times it matched/ how many test cases\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the dataset\",accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468703f-f222-4bb2-b957-c14d1e788c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c036797d-d492-474e-b0e4-e080597978aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "\n",
    "def keras_to_frozen_pb(model_in_path, \n",
    "                       model_out_path,\n",
    "                       custom_object_dict=None,\n",
    "                       tensor_out_name=None,\n",
    "                       tensorboard_dir=None):\n",
    "    \"\"\"\n",
    "    Converter that transforms keras model to frozen pb model\n",
    "    \n",
    "    Args:\n",
    "        model_in_path (str): Input model path (.h5) \n",
    "        model_out_path (str): Output model path (dir)\n",
    "        tensor_out_name (str, optional): Specified name of output tensor. \n",
    "                                         If None, it will get default tensor name from keras model.\n",
    "                                         Defaults to None.\n",
    "        tensorboard_dir (str, optional): Output tensorboard dir path for inspecting output model graph.\n",
    "                                         If None, it doesn't generate. \n",
    "                                         Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        sess = tf.compat.v1.Session()\n",
    "        K.set_session(sess)\n",
    "        K.set_learning_phase(0)\n",
    "\n",
    "        # load the model to graph and sess\n",
    "        model = tf.keras.models.load_model(model_in_path, custom_objects=custom_object_dict)\n",
    "\n",
    "        # get the tensor_out_name \n",
    "        if tensor_out_name is None:\n",
    "            if len(model.outputs) > 1:\n",
    "                raise NameError(\"the model has multiple output tensor. Need to specify output tensor name.\")\n",
    "            else:\n",
    "                tensor_out_name = model.outputs[0].name.split(\":\")[0]\n",
    "\n",
    "        # freeze the graph\n",
    "        graphdef = tf.compat.v1.graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [tensor_out_name])\n",
    "        graphdef = tf.compat.v1.graph_util.remove_training_nodes(graphdef)\n",
    "        graph_io.write_graph(graphdef, './', model_out_path, as_text=False)\n",
    "\n",
    "\t# output tensorboard graph \n",
    "    if not tensorboard_dir is None:\n",
    "        with tf.compat.v1.Graph().as_default():\n",
    "            tf.compat.v1.summary.FileWriter(logdir=tensorboard_dir, graph_def=graphdef)\n",
    "    \n",
    "    return tensor_out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a99fd7-2258-416f-8532-816fe079ff06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a22116-bf1a-4120-974e-c6e5ebcacb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.backend.set_session(session)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3849e6-0a2a-4265-b105-5f4b4297d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferianda/.local/lib/python3.8/site-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "2022-09-12 14:10:21.140516: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20771/128237676.py:42: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/ferianda/.local/lib/python3.8/site-packages/tensorflow/python/framework/convert_to_constants.py:936: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "WARNING:tensorflow:From /tmp/ipykernel_20771/128237676.py:43: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n",
      "the output node name is: dense_129/Softmax\n"
     ]
    }
   ],
   "source": [
    "input_keras_model = \"model.h5\"\n",
    "output_pb_model = \"model_frozen.pb\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    node_out_name = keras_to_frozen_pb(model_in_path = input_keras_model, model_out_path = output_pb_model)\n",
    "    print(\"the output node name is:\", node_out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe3c96dc-babd-42c2-abba-9aca815cb52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import uff\n",
    "import tensorrt as trt \n",
    "\n",
    "\n",
    "def frozen_pb_to_plan(model_path, \n",
    "                      output_path,\n",
    "                      tensor_in_name,\n",
    "                      tensor_out_name, \n",
    "                      input_size,\n",
    "                      data_type=trt.float64,\n",
    "                      max_batch_size=1,\n",
    "                      max_workspace=1<<30,\n",
    "                      tensorboard_dir=None):\n",
    "\n",
    "    # infer with pb model\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.io.gfile.GFile(model_path, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    # print(graph_def)\n",
    "    \n",
    "    # convert TF frozen graph to uff model\n",
    "    uff_model = uff.from_tensorflow_frozen_model(model_path, [tensor_out_name])\n",
    "    # print(uff_model)\n",
    "    \n",
    "    # create uff parser\n",
    "    parser = trt.UffParser()\n",
    "    parser.register_input(tensor_in_name, input_size)\n",
    "    parser.register_output(tensor_out_name)\n",
    "    \n",
    "\n",
    "    # create trt logger and builder\n",
    "    trt_logger = trt.Logger(trt.Logger.INFO)\n",
    "    builder = trt.Builder(trt_logger)\n",
    "    builder.max_batch_size = max_batch_size\n",
    "    builder.max_workspace_size = max_workspace\n",
    "    # config.set_flag(trt.BuilderFlag.TF16)\n",
    "    builder.fp16_mode = (data_type == trt.float16)\n",
    "\n",
    "    # parse the uff model to trt builder\n",
    "    # explicit_batch = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "    network = builder.create_network()\n",
    "    parser.parse_buffer(uff_model, network)\n",
    "\n",
    "    # build optimized inference engine\n",
    "    engine = builder.build_cuda_engine(network)\n",
    "\n",
    "    # profile = builder.create_optimization_profile()\n",
    "    # print(profile)\n",
    "    # profile.set_shape_input(tensor_in_name, (1,1,4), (1,1,4), (1,1,4))\n",
    "    # print(profile.get_shape_input(tensor_in_name))\n",
    "    # config = builder.create_builder_config()\n",
    "    # config.add_optimization_profile(profile)\n",
    "    \n",
    "    # print(\"======\")\n",
    "    # print(profile.get_shape)\n",
    "    \n",
    "    # trt_model_engine = builder.build_engine(network, config)\n",
    "    # save inference engine\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98bb92d7-8464-4292-97c4-be30d930c335",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorrt' has no attribute 'float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m input_node_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_19\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m output_node_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense_129/Softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m frozen_pb_to_plan(pb_model_path,\n\u001b[1;32m     17\u001b[0m                   plan_model_path,\n\u001b[1;32m     18\u001b[0m                   input_node_name,\n\u001b[1;32m     19\u001b[0m                   output_node_name,\n\u001b[1;32m     20\u001b[0m                   (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m---> 21\u001b[0m                   data_type\u001b[38;5;241m=\u001b[39m\u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m, \u001b[38;5;66;03m# change this for different TRT precision\u001b[39;00m\n\u001b[1;32m     22\u001b[0m                   max_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m31\u001b[39m,\n\u001b[1;32m     23\u001b[0m                   max_workspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m<<\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorrt' has no attribute 'float64'"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import tensorrt as trt\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "# H, W, C = 4\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    '''\n",
    "    generate the inference engine \n",
    "    '''\n",
    "    pb_model_path = \"model_frozen.pb\"\n",
    "    plan_model_path = \"model.plan\"\n",
    "    input_node_name = \"input_19\"\n",
    "    output_node_name = \"dense_129/Softmax\"\n",
    "\n",
    "    frozen_pb_to_plan(pb_model_path,\n",
    "                      plan_model_path,\n",
    "                      input_node_name,\n",
    "                      output_node_name,\n",
    "                      (1,1,4),\n",
    "                      data_type=trt.float64, # change this for different TRT precision\n",
    "                      max_batch_size=31,\n",
    "                      max_workspace=1<<30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c692959b-fe5a-451b-9753-ec68e3e8086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output name = \n",
      "dense_129/Softmax\n",
      "\n",
      "Input name = \n",
      "input_12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__ # TF1.15.5\n",
    "\n",
    "gf = tf.compat.v1.GraphDef()\n",
    "m_file = open('model_frozen.pb','rb')\n",
    "gf.ParseFromString(m_file.read())\n",
    " \n",
    "with open('somefile.txt', 'a') as the_file:\n",
    "   for n in gf.node:\n",
    "       the_file.write(n.name+'\\n')\n",
    " \n",
    "file = open('somefile.txt','r')\n",
    "data = file.readlines()\n",
    "print(\"output name = \")\n",
    "print(data[len(data)-1])\n",
    " \n",
    "print(\"Input name = \")\n",
    "file.seek ( 0 )\n",
    "print(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4d04b-d11d-4696-8143-b09475edfbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "trt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6493c-4f16-46dd-92e1-c4d42dd20310",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nvidia-tensorrt==7.2.* --index-url https://pypi.ngc.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3a98f-35c3-4a61-85db-3347b0910601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07748055, 0.07941484, 0.0885422 , 0.08627246])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
